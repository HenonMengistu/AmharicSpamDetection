{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPLEMENTATION OF THE FINAL MODEL USING A WEB APP CAN BE FOUND IN THE FOLLOWING LINK http://bit.ly/HenonAminaAmharicSmS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This program detects if an SMS is Spam or not\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data \n",
    "dataframe = pd.read_excel(\"togezer.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 sms label\n",
      "0           አይ እዛ ሚማር አይመስለኝም . እዛ አካባቢ ነው ግን የሚኖረው    ham\n",
      "1    ወንድሜ እንኳ አያናግረኝም።  እንደ ኤች አይ ቪ በሽተኛ አድርገው ይይዙኛል   ham\n",
      "2                                                NaN   ham\n",
      "3  በቅርቡ ወደ ቤት እመለሳለሁ እናም ዛሬ ስለዚህ ነገር ድጋሚ ማውራት አልፈ...   ham\n",
      "4  ለዚህ እስትንፋስ ላመሰግናችሁ ትክክለኛዎቹን ቃላት እየፈለግኩ ነው ፡፡ እ...   ham\n"
     ]
    }
   ],
   "source": [
    "#print some of the data \n",
    "print(dataframe.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sms', 'label'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get column name \n",
    "dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1002, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get column shape \n",
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1002 entries, 0 to 1001\n",
      "Data columns (total 2 columns):\n",
      "sms      993 non-null object\n",
      "label    1002 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 15.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>993</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>979</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>አሁን ብቻ 1 ጊዜ ከላኩ በቂ ነው!ያውም በነፃ!የመቄዶንያ አባል ይሁኑ!1...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>2</td>\n",
       "      <td>544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      sms label\n",
       "count                                                 993  1002\n",
       "unique                                                979     2\n",
       "top     አሁን ብቻ 1 ጊዜ ከላኩ በቂ ነው!ያውም በነፃ!የመቄዶንያ አባል ይሁኑ!1...  spam\n",
       "freq                                                    2   544"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chceck the new shape\n",
    "dataframe.info()\n",
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sms      9\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the number of missing data for each coloum(NAN, NAN, na)\n",
    "dataframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encode=LabelEncoder()\n",
    "label_new=encode.fit_transform(dataframe['label'])\n",
    "label_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools\n",
    "def clean_data(sentence):\n",
    "    ## removing web links\n",
    "    s = [ re.sub(r'http\\S+', '', sentence.lower())]\n",
    "    s = [''.join(''.join(s)[:2] for _, s in itertools.groupby(s[0]))]\n",
    "\n",
    "    ## removing punctuations from the code \n",
    "    s = [remove_punctuations(s[0])]\n",
    "    s = [ re.sub('(ሃ|ኃ|ሓ|ሀ|ሐ|ኀ)','ሀ',s[0])]\n",
    "    s = [ re.sub('(ሁ|ኁ|ሑ)','ሁ',s[0])]\n",
    "    s = [ re.sub('(ሂ|ኂ|ሒ)','ሂ',s[0])]\n",
    "    s = [ re.sub('(ሄ|ኄ|ሔ)','ሄ',s[0])]\n",
    "    s = [ re.sub('(ህ|ኅ|ሕ)','ህ',s[0])]\n",
    "    s = [ re.sub('(ሆ|ኆ|ሖ)','ሆ',s[0])]\n",
    "    \n",
    "    s = [ re.sub('(ሰ|ሠ)','ሰ',s[0])]\n",
    "    s = [ re.sub('(ሱ|ሡ)','ሱ',s[0])]\n",
    "    s = [ re.sub('(ሲ|ሢ)','ሲ',s[0])]\n",
    "    s = [ re.sub('(ሳ|ሣ)','ሳ',s[0])]\n",
    "    s = [ re.sub('(ሴ|ሤ)','ሴ',s[0])]\n",
    "    s = [ re.sub('(ስ|ሥ)','ስ',s[0])]\n",
    "    s = [ re.sub('(ሶ|ሦ)','ሶ',s[0])]\n",
    "    \n",
    "    s = [ re.sub('(አ|ኣ|ዐ|ዓ)','አ',s[0])]\n",
    "    s = [ re.sub('(ኡ|ዑ)','ኡ',s[0])]\n",
    "    s = [ re.sub('(ኢ|ዒ)','ኢ',s[0])]\n",
    "    s = [ re.sub('(ኤ|ዔ)','ኤ',s[0])]\n",
    "    s = [ re.sub('(እ|ዕ)','እ',s[0])]\n",
    "    s = [ re.sub('(ኦ|ዖ)','ኦ',s[0])]\n",
    "    \n",
    "    s = [ re.sub('(ጸ|ፀ)','ፀ',s[0])]\n",
    "    s = [ re.sub('(ጹ|ፁ)','ፁ',s[0])]\n",
    "    s = [ re.sub('(ጺ|ፂ)','ፂ',s[0])]\n",
    "    s = [ re.sub('(ጻ|ፃ)','ፃ',s[0])]\n",
    "    s = [ re.sub('(ጼ|ፄ)','ፄ',s[0])]\n",
    "    s = [ re.sub('(ጽ|ፅ)','ፅ',s[0])]\n",
    "    s = [ re.sub('(ጾ|ፆ)','ፆ',s[0])]\n",
    "    return s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(my_str):\n",
    "    punctuations = '''!()-[]{};:'\"\\,./?@#$%^&@*_~።፣፤፥?፤፡'''\n",
    "    no_punct = \"\"\n",
    "    for char in my_str:\n",
    "       if char not in punctuations:\n",
    "           no_punct = no_punct + char\n",
    "    return no_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'የጠቅላላ እውቀት ክህሎቶን ከፍ ለማድረግ እንዲሁምሀ  የፋይናሀንስ እና የቢዝነስ ምክር ለማግኘት ወደ 6642 ok ብለው በነፃ ይላኩ'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sample Sentence to be cleaned\n",
    "sentence=\"የጠቅላላ ዕ፡ውቀት ክህሎቶን ከፍ ለማድረግ እንዲሁምሓ  የፋይናኀንስ እና የቢዝነስ ምክር ለማግኘት ወደ 6642 Ok ብለው በነጻ ይላኩ::\"\n",
    "\n",
    "## Using clean_data function\n",
    "clean_data(sentence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(0,len(dataframe[\"sms\"])):\n",
    "    dataframe.loc[index,\"sms\"] = clean_data(str(dataframe[\"sms\"].iloc[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 አይ እዛ ሚማር አይመስለኝም  እዛ አካባቢ ነው ግን የሚኖረው \n",
       "1          ወንድሜ እንኳ አያናግረኝም  እንደ ኤች አይ ቪ በሽተኛ አድርገው ይይዙኛል\n",
       "2                                                     nan\n",
       "3       በቅርቡ ወደ ቤት እመለሳለሁ እናም ዛሬ ስለዚህ ነገር ድጋሚ ማውራት አልፈ...\n",
       "4       ለዚህ እስትንፋስ ላመሰግናችሁ ትክክለኛዎቹን ቃላት እየፈለግኩ ነው  እኔ ...\n",
       "                              ...                        \n",
       "997                          ቀላል አደል ሴን ተመርጧል ማለት ጥሩ ነው  \n",
       "998                                 የካቲት ላይ ፈተና መውሰድ አለብኝ\n",
       "999     አዎ ብታደርገው መክራለው በኤቲኤምህ መመዝግብ የምትችል ይመስለኛል አርግጠ...\n",
       "1000                                    ጣጣ የለውም ጊዜሽን ውሰጅ \n",
       "1001                                       ማውራት ፈልጋለው ደውል\n",
       "Name: sms, Length: 1002, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['sms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>0412</th>\n",
       "      <th>0512</th>\n",
       "      <th>058100181178</th>\n",
       "      <th>0912603853</th>\n",
       "      <th>0921452394</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10000</th>\n",
       "      <th>...</th>\n",
       "      <th>ፒጵፒጵፒፒጵበ</th>\n",
       "      <th>ፒጵፒጵፒፒጵየእርሶ</th>\n",
       "      <th>ፓምፕ</th>\n",
       "      <th>ፓርቲ</th>\n",
       "      <th>ፓኪ</th>\n",
       "      <th>ፕላዛ</th>\n",
       "      <th>ፕራቡ</th>\n",
       "      <th>ፕሮጀክቶች</th>\n",
       "      <th>ፕሮግራም</th>\n",
       "      <th>ፖስታ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1002 rows × 5219 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       00  0412  0512  058100181178  0912603853  0921452394   10  100  1000  \\\n",
       "0     0.0   0.0   0.0           0.0         0.0         0.0  0.0  0.0   0.0   \n",
       "1     0.0   0.0   0.0           0.0         0.0         0.0  0.0  0.0   0.0   \n",
       "2     0.0   0.0   0.0           0.0         0.0         0.0  0.0  0.0   0.0   \n",
       "3     0.0   0.0   0.0           0.0         0.0         0.0  0.0  0.0   0.0   \n",
       "4     0.0   0.0   0.0           0.0         0.0         0.0  0.0  0.0   0.0   \n",
       "...   ...   ...   ...           ...         ...         ...  ...  ...   ...   \n",
       "997   0.0   0.0   0.0           0.0         0.0         0.0  0.0  0.0   0.0   \n",
       "998   0.0   0.0   0.0           0.0         0.0         0.0  0.0  0.0   0.0   \n",
       "999   0.0   0.0   0.0           0.0         0.0         0.0  0.0  0.0   0.0   \n",
       "1000  0.0   0.0   0.0           0.0         0.0         0.0  0.0  0.0   0.0   \n",
       "1001  0.0   0.0   0.0           0.0         0.0         0.0  0.0  0.0   0.0   \n",
       "\n",
       "      10000  ...  ፒጵፒጵፒፒጵበ  ፒጵፒጵፒፒጵየእርሶ  ፓምፕ  ፓርቲ   ፓኪ  ፕላዛ  ፕራቡ  ፕሮጀክቶች  \\\n",
       "0       0.0  ...       0.0          0.0  0.0  0.0  0.0  0.0  0.0     0.0   \n",
       "1       0.0  ...       0.0          0.0  0.0  0.0  0.0  0.0  0.0     0.0   \n",
       "2       0.0  ...       0.0          0.0  0.0  0.0  0.0  0.0  0.0     0.0   \n",
       "3       0.0  ...       0.0          0.0  0.0  0.0  0.0  0.0  0.0     0.0   \n",
       "4       0.0  ...       0.0          0.0  0.0  0.0  0.0  0.0  0.0     0.0   \n",
       "...     ...  ...       ...          ...  ...  ...  ...  ...  ...     ...   \n",
       "997     0.0  ...       0.0          0.0  0.0  0.0  0.0  0.0  0.0     0.0   \n",
       "998     0.0  ...       0.0          0.0  0.0  0.0  0.0  0.0  0.0     0.0   \n",
       "999     0.0  ...       0.0          0.0  0.0  0.0  0.0  0.0  0.0     0.0   \n",
       "1000    0.0  ...       0.0          0.0  0.0  0.0  0.0  0.0  0.0     0.0   \n",
       "1001    0.0  ...       0.0          0.0  0.0  0.0  0.0  0.0  0.0     0.0   \n",
       "\n",
       "      ፕሮግራም  ፖስታ  \n",
       "0       0.0  0.0  \n",
       "1       0.0  0.0  \n",
       "2       0.0  0.0  \n",
       "3       0.0  0.0  \n",
       "4       0.0  0.0  \n",
       "...     ...  ...  \n",
       "997     0.0  0.0  \n",
       "998     0.0  0.0  \n",
       "999     0.0  0.0  \n",
       "1000    0.0  0.0  \n",
       "1001    0.0  0.0  \n",
       "\n",
       "[1002 rows x 5219 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#s=dataframe[\"sms\"].iloc[0]\n",
    "#tokens = nltk.tokenize.word_tokenize(s)\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "tfvect=TfidfVectorizer(max_df=0.7)\n",
    "trans=tfvect.fit_transform(dataframe['sms'])\n",
    "messages_bow=pd.DataFrame(trans.toarray(),columns=tfvect.get_feature_names())\n",
    "messages_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into 80% training and 20% testing \n",
    "X_train, X_test, y_train, y_test = train_test_split(dataframe['sms'], label_new, test_size=0.20 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=tfvect.fit_transform(X_train)\n",
    "_test=tfvect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and train the naive bayes classifier\n",
    "classifier = MultinomialNB().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the pridiction\n",
    "prediction=classifier.predict(_test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the actual values\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.04%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "score=accuracy_score(y_test,prediction)\n",
    "print(f'Accuracy: {round(score*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[ 82  16]\n",
      " [  0 103]]\n",
      "\n",
      "Accuraccy:  0.9203980099502488\n"
     ]
    }
   ],
   "source": [
    " #Evaluate the model on the training data set \n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test,prediction))\n",
    "print()\n",
    "print('Accuraccy: ', accuracy_score(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "alg=LogisticRegression()\n",
    "alg.fit(X_train,y_train)\n",
    "pred=alg.predict(_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.02%\n"
     ]
    }
   ],
   "source": [
    "score=accuracy_score(y_test,pred)\n",
    "print(f'Accuracy: {round(score*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[94  4]\n",
      " [ 4 99]]\n",
      "\n",
      "Accuraccy:  0.9601990049751243\n"
     ]
    }
   ],
   "source": [
    " #Evaluate the model on the training data set \n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test,pred))\n",
    "print()\n",
    "print('Accuraccy: ', accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to wss://anvil.works/uplink\n",
      "Anvil websocket open\n",
      "Authenticated OK\n",
      "Reconnecting Anvil Uplink...\n"
     ]
    }
   ],
   "source": [
    "import anvil.server\n",
    "anvil.server.connect(\"MVZAD6IJSYGRWFK3JVXOMZ2H-PUBNCWAUKVX7YP7P\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import anvil.server\n",
    "#saving model\n",
    "pickle.dump(alg, open(r'model_new9.pickle', 'wb'))\n",
    "@anvil.server.callable\n",
    "def predict_model(q):\n",
    "    q=tfvect.transform([q])\n",
    "    Modelr = pickle.load(open(r'model_new9.pickle', 'rb'))\n",
    "    predictions=Modelr.predict(q)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
